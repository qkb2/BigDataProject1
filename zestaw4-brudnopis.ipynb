{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "861b6d4a-0de6-42ba-97a5-beef1f82f292",
   "metadata": {},
   "source": [
    "# Projekt Apache Spark - brudnopis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b301ae8-ceff-4dbf-8d04-75bb4eb52480",
   "metadata": {},
   "source": [
    "# Wprowadzenie\n",
    "\n",
    "Wykorzystując ten notatnik jako szablon zrealizuj projekt Apache Spark zgodnie z przydzielonym zestawem. \n",
    "\n",
    "Kilka uwag:\n",
    "\n",
    "* Nie modyfikuj ani nie usuwaj paragrafów *markdown* w tym notatniku, chyba że wynika to jednoznacznie z instrukcji. \n",
    "* Istniejące paragrafy zawierające *kod* uzupełnij w razie potrzeby zgodnie z instrukcjami\n",
    "    - nie usuwaj ich\n",
    "    - nie usuwaj zawartych w nich instrukcji oraz kodu\n",
    "    - nie modyfikuj ich, jeśli instrukcje jawnie tego nie nakazują\n",
    "* Możesz dodawać nowe paragrafy zarówno zawierające kod jak i komentarze dotyczące tego kodu (markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d12f1-1013-4c74-b6aa-686ccfcbdd5c",
   "metadata": {},
   "source": [
    "# Treść projektu\n",
    "\n",
    "# Zestaw 4 – imdb-persons\n",
    "\n",
    "## Dwa zbiory danych \n",
    "\n",
    "### `datasource1` – informacje na temat najważniejszych osób zaangażowanych w poszczególne filmy (1)\n",
    "\n",
    "Dane mają format `TSV`, pliki nie posiadają nagłówka.\n",
    "\n",
    "Pola w pliku:\n",
    "\n",
    "0. `tconst` – identyfikator filmu\n",
    "1. `ordering` - numer kolejny osoby w filmie\n",
    "2. `nconst` - identyfikator osoby\n",
    "3. `role` - rola osoby w filmie\n",
    "4. `job` - nazwa zawodu (jeśli dotyczy, w przeciwnym wypadku `\\N`)\n",
    "5. `characters` - nazwa postaci jaką grała osoba (jeśli dotyczy, w przeciwnym wypadku `\\N`)\n",
    "\n",
    "### `datasource4` – informacje na temat osób zaangażowanych w filmach (4)\n",
    "\n",
    "Dane mają format `TSV`, każdy z plików posiada nagłówek.\n",
    "\n",
    "Pola w pliku:\n",
    "\n",
    "0. `nconst` – identyfikator osoby\n",
    "1. `primaryName` – nazwa (imię i nazwisko) osoby\n",
    "2. `birthYear` – rok urodzenia\n",
    "3. `deathYear` – rok śmierci (`\\N`, jeśli nie dotyczy)\n",
    "4. `primaryProfession` – główne profesje osoby\n",
    "5. `knownForTitles` – identyfikatory filmów, z których ta osoba jest znana\n",
    "\n",
    "## Misja główna\n",
    "\n",
    "### Cel przetwarzania \n",
    "\n",
    "Dla czterech najbardziej popularnych profesji należy wyznaczyć trzy osoby, które były zaangażowane w największą liczbę filmów zgodnie z tą profesją. \n",
    "W obliczeniach nie uwzględniamy filmów, dla których nie ma zdefiniowanej \"pełnej obsady\". \n",
    "\n",
    "Film z pełną obsadą to taki, który posiada: \n",
    "- co najmniej jednego aktora (`role in (actor, actress, self)`), \n",
    "- co najmniej jednego reżysera (`role = director`) oraz \n",
    "- osoby pełniące co najmniej dwie inne dowolne role. \n",
    "\n",
    "Ostateczny wynik powinien zawierać następujące atrybuty: \n",
    "- `profession` – profesja\n",
    "- `primaryName` – nazwa osoby\n",
    "- `movies` – liczba filmów \n",
    "\n",
    "Sugerowany schemat wyniku \n",
    "```\n",
    "root\n",
    " |-- profession: string (nullable = false)\n",
    " |-- primaryName: string (nullable = true)\n",
    " |-- movies: long (nullable = false)\n",
    "```\n",
    "\n",
    "Uwagi\n",
    "- Przez profesje rozumiemy wartości występujące jako rozdzielane przecinkami składowe w `primaryProfession` wyłączając z nich wartość `\"miscellaneous\"`\n",
    "- Poziom popularności profesji wyznaczany jest wyznaczany jest na podstawie tego ile osób posiada daną profesję na swojej liście profesji w `primaryProfession`\n",
    " \n",
    "## Misje poboczne \n",
    "\n",
    "### Misja 1\n",
    "Przeanalizuj dane dotyczące zmarłych osób wyznacz ile osób żyło określoną liczbę lat. Podaj ilu z nich było aktorami, a ilu reżyserami. \n",
    "\n",
    "Wynik ma zawierać następujące kolumny:\n",
    "- `age` – liczba przeżytych lat\n",
    "- `persons` – liczba osób, które przeżyły określoną liczbę lat\n",
    "- `actors` – liczba aktorów (`primaryProfession` zawiera jedną z wartości: `actors`, `actress`). \n",
    "- `directors` - liczba reżyserów (`primaryProfession` zawiera wartość `director`).\n",
    "\n",
    "### Misja 2\n",
    "Wśród osób, które urodziły się w ubiegłym wieku i które przeżyły ponad 70 lat, wyznacz te trzy, które za brały udział w największej liczbie filmów. Określ w ilu filmach byli oni aktorami oraz ile z tych filmów zostało przez nich wyreżyserowane. \n",
    "\n",
    "Wynik ma zawierać następujące kolumny:\n",
    "- `primaryName` – nazwa (imię i nazwisko) osoby\n",
    "- `birthYear` – data urodzenia \n",
    "- `age` – wiek \n",
    "- `filmCount` – liczba filmów w których osoba brała udział\n",
    "- `filmCountAsActor` – liczba filmów, w których osoba była aktorem/aktorką (role in (`actors`, `actress`, `self`)). \n",
    "- `FilmCountAsDirector` - liczba filmów, w których osoba była reżyserem/reżyserką (`role` = `director`).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oczekiwany wynik dla misji głównej:\n",
    "+----------+------------------+------+\n",
    "|profession|       primaryName|movies|\n",
    "+----------+------------------+------+\n",
    "|     actor|Luis Eduardo Motoa|  3559|\n",
    "|     actor|         Ronit Roy|  2602|\n",
    "|     actor|       Dilip Joshi|  2385|\n",
    "|   actress|Luz Stella Luengas|  3636|\n",
    "|   actress| Rohini Hattangadi|  3240|\n",
    "|   actress|        Kavita Lad|  3204|\n",
    "|  producer|     Shobha Kapoor| 11833|\n",
    "|  producer|       Ekta Kapoor|  8826|\n",
    "|  producer| Valentin Pimstein|  6081|\n",
    "|    writer|       Tony Warren|  6153|\n",
    "|    writer|      Delia Fiallo|  6132|\n",
    "|    writer|     Sampurn Anand|  5205|\n",
    "+----------+------------------+------+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dff51e",
   "metadata": {},
   "source": [
    "Miejsca docelowe dla wyników misji głównych:\n",
    "* Spark Core - RDD: katalog HDFS /tmp/output1, pliki w formacie SequenceFile serializowane przez Pickle (saveAsPickleFile).\n",
    "* Spark Core - DataFrame: tabela Delta Lake output2.\n",
    "* Spark SQL - Pandas API on Spark: plik /tmp/output3.json w lokalnym systemie plików w formacie json (json lines)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc4ff6-4d43-49ed-a0d1-8b6988eaec16",
   "metadata": {},
   "source": [
    "# Zestaw 0 – wzorzec\n",
    "\n",
    "**Uwaga**\n",
    "\n",
    "- W ramach wzorca nie są spełnione żadne reguły projektu. \n",
    "- Brak konsekwencji w wykorzystaniu właściwego API w ramach poszczególnych części\n",
    "- Zadanie *misji głównej* polega na zliczeniu słówek.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e128e43-6cce-4ffa-9609-9fae4b164ae9",
   "metadata": {},
   "source": [
    "# Działania wstępne \n",
    "\n",
    "Uruchom poniższy paragraf, aby utworzyć obiekty kontekstu Sparka. Jeśli jest taka potrzeba dostosuj te polecenia. Pamiętaj o potrzebnych bibliotekach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fb1050-386f-4398-ba5a-b45f5065d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark session & context\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695a354-52bc-4bba-8222-7121bf07ae90",
   "metadata": {},
   "source": [
    "W poniższym paragrafie uzupełnij polecenia definiujące poszczególne zmienne. \n",
    "\n",
    "Pamiętaj abyś:\n",
    "\n",
    "* w późniejszym kodzie, dla wszystkich cześci projektu, korzystał z tych zdefiniowanych zmiennych. Wykorzystuj je analogicznie jak parametry\n",
    "* przed ostateczną rejestracją projektu usunął ich wartości, tak aby nie pozostawiać w notatniku niczego co mogłoby identyfikować Ciebie jako jego autora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e883af01-7117-4faa-a840-7ff807a195d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pełna ścieżka do katalogu w zasobniku zawierającego podkatalogi `datasource1` i `datasource4` \n",
    "# z danymi źródłowymi\n",
    "input_dir = \"/local_files/input\" # BRUDNOPIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9aa57c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n"
     ]
    }
   ],
   "source": [
    "!ls /local_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4601cc7a-3ed5-47e2-994f-ebec642049b5",
   "metadata": {},
   "source": [
    "Nie modyfikuj poniższych paragrafów. Wykonaj je i używaj zdefniowanych poniżej zmiennych jak parametrów Twojego programu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6167e297-01ed-463e-bb81-9104d7cf7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "# ścieżki dla danych źródłowych \n",
    "datasource1_dir = input_dir + \"/datasource1\"\n",
    "datasource4_dir = input_dir + \"/datasource4\"\n",
    "\n",
    "# nazwy i ścieżki dla wyników dla misji głównej \n",
    "# część 1 (Spark Core - RDD) \n",
    "rdd_result_dir = \"/tmp/output1\"\n",
    "\n",
    "# część 2 (Spark SQL - DataFrame)\n",
    "df_result_table = \"output2\"\n",
    "\n",
    "# część 3 (Pandas API on Spark)\n",
    "ps_result_file = \"/tmp/output3.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36e0314-a4ac-4096-9e4b-23fd4a73e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "import os\n",
    "def remove_file(file):\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "\n",
    "remove_file(\"metric_functions.py\")\n",
    "remove_file(\"tools_functions.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b4b8e00-10ae-47dc-b623-d1dacbe9c86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3322"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "import requests\n",
    "r = requests.get(\"https://jankiewicz.pl/bigdata/metric_functions.py\", allow_redirects=True)\n",
    "open('metric_functions.py', 'wb').write(r.content)\n",
    "r = requests.get(\"https://jankiewicz.pl/bigdata/tools_functions.py\", allow_redirects=True)\n",
    "open('tools_functions.py', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b003d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRUDNOPIS\n",
    "from metric_functions import *\n",
    "from tools_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a433894-dc97-46f2-be51-9f40fa36894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "%run metric_functions.py\n",
    "%run tools_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3a9dc-ac3b-4316-abb9-365caa1d7185",
   "metadata": {},
   "source": [
    "Poniższe paragrafy mają na celu usunąć ewentualne pozostałości poprzednich uruchomień tego lub innych notatników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08091c72-937f-41c2-9afe-d1505862bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deleted directory: /tmp/output1\n"
     ]
    }
   ],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "# usunięcie miejsca docelowego dla część 1 (Spark Core - RDD) \n",
    "delete_dir(spark, rdd_result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e863c0-c824-47bd-b53a-ce3b1fd6d453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table output2 does not exist.\n",
      "Path file:/home/jovyan/spark-warehouse/output2 does not exist.\n"
     ]
    }
   ],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "# usunięcie miejsca docelowego dla część 2 (Spark SQL - DataFrame) \n",
    "drop_table(spark, df_result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72956a1a-da48-4d2b-a07a-e03d56431d6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# NIE ZMIENIAĆ\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# usunięcie miejsca docelowego dla część 3 (Pandas API on Spark) \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mremove_file\u001b[49m(ps_result_file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remove_file' is not defined"
     ]
    }
   ],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "# usunięcie miejsca docelowego dla część 3 (Pandas API on Spark) \n",
    "remove_file(ps_result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e423d4-92b8-4161-98da-1a867f86d780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://e19d8f586eec:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0df83e1790>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14faf05b-6c52-4b02-b2e5-2ddb3f38c704",
   "metadata": {},
   "source": [
    "***Uwaga!***\n",
    "\n",
    "Uruchom poniższy paragraf i sprawdź czy adres, pod którym dostępny *Apache Spark Application UI* jest poprawny wywołując następny testowy paragraf. \n",
    "\n",
    "W razie potrzeby określ samodzielnie poprawny adres, pod którym dostępny *Apache Spark Application UI*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32acf3d2-ec4e-469d-bb0b-5f260c2c8e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:4040'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adres URL, pod którym dostępny Apache Spark Application UI (REST API)\n",
    "# \n",
    "spark_ui_address = extract_host_and_port(spark, \"http://localhost:4040\")\n",
    "spark_ui_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c2329e-1d7a-465f-a23b-333f95bf7deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numTasks': 0,\n",
       " 'numActiveTasks': 0,\n",
       " 'numCompleteTasks': 0,\n",
       " 'numFailedTasks': 0,\n",
       " 'numKilledTasks': 0,\n",
       " 'numCompletedIndices': 0,\n",
       " 'executorDeserializeTime': 0,\n",
       " 'executorDeserializeCpuTime': 0,\n",
       " 'executorRunTime': 0,\n",
       " 'executorCpuTime': 0,\n",
       " 'resultSize': 0,\n",
       " 'jvmGcTime': 0,\n",
       " 'resultSerializationTime': 0,\n",
       " 'memoryBytesSpilled': 0,\n",
       " 'diskBytesSpilled': 0,\n",
       " 'peakExecutionMemory': 0,\n",
       " 'inputBytes': 0,\n",
       " 'inputRecords': 0,\n",
       " 'outputBytes': 0,\n",
       " 'outputRecords': 0,\n",
       " 'shuffleRemoteBlocksFetched': 0,\n",
       " 'shuffleLocalBlocksFetched': 0,\n",
       " 'shuffleFetchWaitTime': 0,\n",
       " 'shuffleRemoteBytesRead': 0,\n",
       " 'shuffleRemoteBytesReadToDisk': 0,\n",
       " 'shuffleLocalBytesRead': 0,\n",
       " 'shuffleReadBytes': 0,\n",
       " 'shuffleReadRecords': 0,\n",
       " 'shuffleWriteBytes': 0,\n",
       " 'shuffleWriteTime': 0,\n",
       " 'shuffleWriteRecords': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testowy paragraf\n",
    "test_metrics = get_current_metrics(spark_ui_address)\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ccca69-c577-440c-aa5c-c9df3a54e127",
   "metadata": {},
   "source": [
    "# Część 1 - Spark Core (RDD)\n",
    "\n",
    "## Misje poboczne\n",
    "\n",
    "W ponizszych paragrafach wprowadź swoje rozwiązania *misji pobocznych*, o ile **nie** chcesz, aby oceniana była *misja główna*. W przeciwnym przypadku **KONIECZNIE** pozostaw je **puste**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af3440-983a-4cac-a8e7-4908b010947c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc37879-e0fa-4c4a-bd0d-4c01c3ecf38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d303a72b-4083-470e-b25d-3224360ee94f",
   "metadata": {},
   "source": [
    "## Misja główna \n",
    "\n",
    "Poniższy paragraf zapisuje metryki przed uruchomieniem Twojego rozwiązania *misji głównej*. \n",
    "\n",
    "Nie musisz go uruchamiać podczas implementacji rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "037689d7-f0ee-4165-bef0-83fa7f3e8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "before_rdd_metrics = get_current_metrics(spark_ui_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23971c0-cec7-4ea8-befb-7f063dce863c",
   "metadata": {},
   "source": [
    "W poniższych paragrafach wprowadź **rozwiązanie** *misji głównej* oparte na *RDD API*. \n",
    "\n",
    "Pamiętaj o wydajności Twojego przetwarzania, *RDD API* tego wymaga. \n",
    "\n",
    "Nie wprowadzaj w poniższych paragrafach żadnego kodu, w przypadku wykorzystania *misji pobocznych*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af00c41-02a9-4a85-b3c6-bc41098edbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie plików tekstowych\n",
    "actor_data = sc.textFile(datasource4_dir)\n",
    "movie_crew_data = sc.textFile(datasource1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7955a5f-386d-47a5-9f6a-3d93a906c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filmy z pełną obsadą\n",
    "movies_data = movie_crew_data.map(lambda line: line.split(\"\\t\")).\\\n",
    "    map(lambda fields: (fields[0], fields[2], fields[3])).\\\n",
    "    groupBy(lambda x: x[0])\n",
    "# Filtr dla filmów\n",
    "def filter_movies(group):\n",
    "    movie_id, entries = group\n",
    "    roles = [entry[2] for entry in entries]\n",
    "    people = set(entry[1] for entry in entries)  # Unique person_ids\n",
    "    has_actor = any(role in {\"actor\", \"actress\", \"self\"} for role in roles)\n",
    "    has_director = \"director\" in roles\n",
    "    return len(people) >= 4 and has_actor and has_director\n",
    "\n",
    "movies_full_cast = movies_data.filter(filter_movies)\n",
    "\n",
    "# Najpopularniejsze profesje\n",
    "profession_counts = actor_data.map(lambda line: line.split(\"\\t\")[4]).\\\n",
    "    flatMap(lambda professions: professions.split(\",\")).\\\n",
    "    filter(lambda profession: profession != \"miscellaneous\").\\\n",
    "    map(lambda profession: (profession, 1)).\\\n",
    "    reduceByKey(lambda x, y: x + y)    \n",
    "top4_professions = profession_counts.takeOrdered(4)\n",
    "\n",
    "# Osoby zaangażowane\n",
    "most_movies_worked_on = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91d77fd7-1f15-4365-ae80-c902aeb55ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis wyniku do pliku pickle\n",
    "word_counts.saveAsPickleFile(rdd_result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "846afd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000  part-00004\tpart-00008  part-00012\tpart-00016\n",
      "part-00001  part-00005\tpart-00009  part-00013\tpart-00017\n",
      "part-00002  part-00006\tpart-00010  part-00014\t_SUCCESS\n",
      "part-00003  part-00007\tpart-00011  part-00015\n",
      "SEQ\u0006!org.apache.hadoop.io.NullWritable\"org.apache.hadoop.io.BytesWritable\u0000\u0000\u0000\u0000\u0000\u0000[�\u0018��dbe{pĉp$!�\u0000\u0000\u0015�\u0000\u0000\u0000\u0000\u0000\u0000\u0015|��\u0000\u0005ur\u0000\u0003[[BK�\u0019\u0015gg�7\u0002\u0000\u0000xp\u0000\u0000\u0000\n",
      "nm0000158\tTom�K\u0001���\u000enm0000159\tTeri�K\u0001���\u000fnm0000166\tHelen�K\u0001���OJones\t1946\t\\N\tactor,director,soundtrack\ttt0106977,tt0477348,tt2398231,tt0443272�K\u0001���TLocklear\t1961\t\\N\tactress,producer,soundtrack\ttt0380623,tt0119695,tt0103491,tt0087262�K\u0001���\u000fnm0000183\tTraci�K\u0001���PPacino\t1940\t\\N\tactor,soundtrack,director\ttt0099422,tt0068646,tt0070666,tt0072890�K\u0001���\u000enm0000200\tBill�K\u0001���QPhillippe\t1974\t\\N\tactor,producer,director\ttt0202677,tt0280707,tt0139134,tt0375679�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001��\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�OPosey\t1968\t\\N\tactress,soundtrack,writer\ttt0348150,tt0134084,tt0359013,tt0106677�K\u0001���PReeves\t1964\t\\N\tactor,producer,soundtrack\ttt0111257,tt0133093,tt0102685,tt0234215�K\u0001���\u000fnm0000208\tMolly�K\u0001���WSilverstone\t1976\t\\N\tactress,producer,soundtrack\ttt0124298,tt0106627,tt0112697,tt0118688�K\u0001���\u0013nm0000230\tSylvester�K\u0001���\u0011nm0000238\tShannon�K\u0001���\u000fnm0000245\tRobin�K\u0001���KJr.\t1924\t1978\twriter,director,actor\ttt0052077,tt0047127,tt0067479,tt0045826�K\u0001���\u0010nm0000266\tUrsula�K\u0001���\u0016nm0000269\tJean-Jacques�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002'�\u0005�\u001c\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�NArdant\t1949\t\\N\tactress,director,writer\ttt0086551,tt0283832,tt0127536,tt0401711�K\u0001���\u000fnm0000281\tScott�K\u0001���\u000fnm0000289\tEllen�K\u0001���GBarkin\t1954\t\\N\tactress,producer\ttt0157503,tt0116277,tt0108330,tt0098273�K\u0001���\\Binoche\t1964\t\\N\tactress,art_department,miscellaneous\ttt0241303,tt0116209,tt0108394,tt1219827�K\u0001���KBlackman\t1925\t\\N\tactress,soundtrack\ttt0243155,tt0057197,tt0058150,tt0054518�K\u0001���QBlair\t1959\t\\N\tactress,soundtrack,producer\ttt0088044,tt0076009,tt0070047,tt0082511�K\u0001���\u0006Bonham�K\f���\u000fnm0000309\tDavid�K\u0001���\u0011nm0000321\tGabriel�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001ƀ\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0011nm0000323\tMichael�K\u0001���TCattrall\t1956\t\\N\tactress,producer,soundtrack\ttt0102975,tt1261945,tt1000774,tt0159206�K\u0001���UChamberlain\t1934\t\\N\tactor,soundtrack,producer\ttt0085101,tt0072308,tt0076299,tt0080274�K\u0001���\u0011nm0000334\tYun-Fat�K\u0001���\u0011nm0000341\tMichael�K\u0001���\u000fnm0000345\tBilly�K\u0001���\u0012nm0000383\tJennifer�K\u0001���\u0010nm0000389\tEmilio�K\u0001���RFisher\t1956\t2016\tactress,soundtrack,writer\ttt0086190,tt0080684,tt2527336,tt0076759�K\u0001���\u0011nm0000403\tBridget�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002e�\u0005�Z\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�QFonda\t1937\t\\N\tactress,producer,soundtrack\ttt3312830,tt0369735,tt0067309,tt0062711�K\u0001���\u0012nm0000405\tMichelle�K\u0001���\u000enm0000414\tTeri�K\u0001���PGertz\t1965\t\\N\tactress,producer,executive\ttt0117998,tt0320970,tt0088128,tt0093437�K\u0001���QGoodman\t1952\t\\N\tactor,soundtrack,producer\ttt0101410,tt1024648,tt1907668,tt1179933�K\u0001���\u0010nm0000423\tSerena�K\u0001���>Grandi\t1958\t\\N\tactress\ttt0104123,tt0089271,tt2358891,tt0089598�K\u0001���\u000fnm0000435\tDaryl�K\u0001���PHarris\t1973\t\\N\tactor,soundtrack,producer\ttt0120201,tt2267998,tt0460649,tt4834206�K\u0001���PHawn\t1945\t\\N\tactress,producer,soundtrack\ttt0104070,tt0116313,tt0093693,tt0116242�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001�\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0010nm0000446\tMariel�K\u0001���\u0011nm0000461\tMichael�K\u0001���\u000fnm0000463\tFamke�K\u0001���\u000fnm0000478\tTawny�K\u0001���MKrige\t1954\t\\N\tactress,producer,writer\ttt0105428,tt0384537,tt1981115,tt0117731�K\u0001���LLee\t1957\t\\N\tdirector,producer,writer\ttt0097216,tt0091939,tt0104797,tt7349662�K\u0001���QLillard\t1970\t\\N\tactor,producer,soundtrack\ttt0331632,tt1033575,tt0267913,tt0133189�K\u0001���NLowe\t1964\t\\N\tactor,producer,soundtrack\ttt0086066,tt0090060,tt0105793,tt0118884�K\u0001���\u000enm0000509\tBela�K\u0001���\u000fnm0000510\tAndie�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002~�\u0005�s\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0012nm0000517\tTerrence�K\u0001���OMalkovich\t1953\t\\N\tactor,producer,writer\ttt0120601,tt0107206,tt1245526,tt0094947�K\u0001���\u0010nm0000521\tSophie�K\u0001���OMarceau\t1966\t\\N\tactress,director,writer\ttt0112573,tt1194616,tt0143145,tt0082100�K\u0001���SMathis\t1970\t\\N\tactress,soundtrack,executive\ttt0110367,tt0144084,tt0115759,tt0108255�K\u0001���\u0010nm0000527\tWalter�K\u0001���YMazar\t1964\t\\N\tactress,make_up_department,producer\ttt0140352,tt0112950,tt0387199,tt1674771�K\u0001���LNelson\t1959\t\\N\tactor,writer,producer\ttt0092106,tt0090060,tt0102526,tt0088847�K\u0001���ONimoy\t1931\t2015\tactor,director,producer\ttt0796366,tt0102975,tt1399103,tt0092007�K\u0001���\u0011nm0000569\tGwyneth�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001�\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u000enm0000576\tSean�K\u0001���QPlumb\t1958\t\\N\tactress,soundtrack,producer\ttt0074376,tt2359024,tt0063878,tt4268054�K\u0001���QPriestley\t1969\t\\N\tactor,producer,director\ttt0098749,tt5722298,tt2334593,tt1558182�K\u0001���\u0010nm0000601\tHarold�K\u0001���QRickman\t1946\t2016\tactor,soundtrack,writer\ttt1201607,tt0095016,tt0102798,tt0177789�K\u0001���\u000enm0000621\tKurt�K\u0001���PSlater\t1963\t\\N\tactress,soundtrack,writer\ttt0088206,tt0089470,tt0093936,tt0101587�K\u0001���\u000enm0000684\tNana�K\u0001���\u000enm0000730\tJohn�K\u0001���\u000enm0000737\tJane�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001��\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�NAmiel\t1948\t\\N\tdirector,producer,writer\ttt0100822,tt0137494,tt0298814,tt0112722�K\u0001���\u000fnm0000754\tKevin�K\u0001���JAnspaugh\t1946\t\\N\tproducer,director\ttt0108002,tt0081873,tt0083483,tt0091217�K\u0001���\u000fnm0000772\tSusan�K\u0001���ZArquette\t1969\t2016\tactress,art_department,producer\ttt0110912,tt0144120,tt0160862,tt0283003�K\u0001���\u0012nm0000805\tClaudine�K\u0001���\u000enm0000807\tJane�K\u0001���NAvary\t1965\t\\N\tproducer,writer,director\ttt0110265,tt0292644,tt7248248,tt0110912�K\u0001���\u000enm0000815\tMili�K\u0001���\u000enm0000825\tMary�K\u0001��e.\u0000\u0000\u0013�\u0000\u0000\u0000\u0000\u0000\u0000\u0013���\u0000\u0005ur\u0000\u0003[[BK�\u0019\u0015gg�7\u0002\u0000\u0000xp\u0000\u0000\u0000\n",
      "nm0001815\tJim�K\u0001��e.\u0000\u0000\u0016�\u0000\u0000\u0000\u0000\u0000\u0000\u0016ͬ�\u0000\u0005ur\u0000\u0003[[BK�\u0019\u0015gg�7\u0002\u0000\u0000xp\u0000\u0000\u0000K\u0001���\u000fnm0001710\tDavid�K\u0001���\u0014nm0001733\tNicollette�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002\u0012�\u0005�\u0007\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0010nm0001752\tSteven�K\u0001���\u000enm0001754\tTodd�K\u0001���MSpano\t1962\t\\N\tactor,director,producer\ttt0085208,tt0086216,tt0088960,tt0106246�K\u0001���\u0010nm0001771\tStella�K\u0001���\u0010nm0001784\tGloria�K\u0001���>Thomas\t1957\t\\N\tactress\ttt0084945,tt1555440,tt0081859,tt0092812�K\u0001���NThomas\t1971\t\\N\tactor,producer,composer\ttt0083866,tt0331811,tt0087065,tt0110322�K\u0001���MTicotin\t1958\t\\N\tactress,miscellaneous\ttt0106856,tt0406759,tt0100802,tt0118880�K\u0001���KTowne\t1934\t\\N\twriter,producer,actor\ttt0096244,tt0117060,tt0073692,tt0071315�K\u0001���actor,soundtrack,director\ttt0087182,tt2096673,tt0098936,tt0090756�K\u0001���\u000enm0001500\tKarl�K\u0001���WMarvin\t1924\t1987\tactor,soundtrack,miscellaneous\ttt0061578,tt0064782,tt0056217,tt0060862�K\u0001���\tElizabeth�Mq\u0005���\u0013nm0001517\tCatherine�K\u0001���\u0012nm0001523\tNatascha�K\u0001���TMcNichol\t1962\t\\N\tactress,soundtrack,producer\ttt0073992,tt0081060,tt0084504,tt0096324�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001p�\u0005�e\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0011nm0001544\tRicardo�K\u0001���\u000enm0001549\tRita�K\u0001���KMoriarty\t1960\t\\N\tactress,soundtrack\ttt0102951,tt0081398,tt0289848,tt1038919�K\u0001���\u000fnm0001554\tErrol�K\u0001���\u000fnm0001572\tDanny�K\u0001���\u000enm0001588\tJack�K\u0001���\u000enm0001596\tPier�K\u0001���RPatinkin\t1952\t\\N\tactor,soundtrack,producer\ttt0099422,tt2543472,tt0093779,tt1796960�K\u0001���\u000fnm0001616\tMekhi�K\u0001���\u0015nm0001626\tChristopher�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001x�\u0005�m\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u000fnm0001629\tKevin�K\u0001���QPotts\t1952\t\\N\tactress,producer,soundtrack\ttt0087332,tt0091790,tt0097428,tt0090418�K\u0001���\u0012nm0001667\tJonathan�K\u0001���RRodriguez\t1968\t\\N\tproducer,writer,director\ttt0287717,tt0458481,tt1077258,tt0104815�K\u0001���\u0010nm0001682\tMickey�K\u0001���\n",
      "nm0002653\tJoe�K\u0001���\u0012nm0002656\tBenedikt�K\u0001���MRoss\t1956\t\\N\twriter,producer,director\ttt0094737,tt1392170,tt0120789,tt0329575�K\u0001��e.\u0000\u0000\u0016[\u0000\u0000\u0000\u0000\u0000\u0000\u0016W��\u0000\u0005ur\u0000\u0003[[BK�\u0019\u0015gg�7\u0002\u0000\u0000xp\u0000\u0000\u0000,production_manager\ttt0110797,tt0118869,tt0116832,tt0117421�K\u0001���\u000enm0002548\tRuby�K\u0001���\u0011nm0002549\tMarcelo�K\u0001���\u0010nm0002584\tAmanda�K\u0001���\u000fnm0002590\tHarry�K\u0001���\u000fnm0002592\tDavid�K\u0001���\u000enm0002593\tRick�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002F�\u0005�;\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�nFactorovich\t\\N\t\\N\tproduction_manager,location_management,miscellaneous\ttt0283897,tt0219449,tt0120275,tt0211347�K\u0001���\u000fnm0002610\tChris�K\u0001���<Roth\t\\N\t\\N\tproduction_designer\ttt0192722,tt0116839,tt0303648�K\u0001���XBerman\t1913\t2006\tproducer,writer,cinematographer\ttt1139293,tt0053961,tt0063893,tt0062551�K\u0001���\u0010nm0002634\tImogen�K\u0001���SHill\t1966\t\\N\tactor,camera_department,writer\ttt1733304,tt0208520,tt0156946,tt0164145�K\u0001���\u0010nm0002646\tSheila�K\u0001���K\u0001���NJr.\t1916\t1968\tassistant_director,actor\ttt0048913,tt0052442,tt0059540,tt0055423�K\u0001���]Natale\t\\N\t\\N\tactor,camera_department,casting_director\ttt0292887,tt6420834,tt0209047,tt0118590�K\u0001���\u000enm0002254\tKing�K\u0001���\u0011nm0002260\tMelissa�K\u0001���_Selen\t1972\t\\N\tproducer,miscellaneous,production_manager\ttt1609159,tt1320352,tt0288861,tt1800338�K\u0001���\u000enm0002282\tJeff�K\u0001���\u000fnm0002284\tSaeed�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002a�\u0005�V\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0011nm0002286\tMichael�K\u0001���\u001fKozlovsky\t\\N\t\\N\tactor\ttt0164204�K\u0001���VThayer\t1971\t\\N\tdirector,cinematographer,writer\ttt0177211,tt0202394,tt0202631,tt0202332�K\u0001���ZMurphy\t1943\t2013\tcinematographer,camera_department\ttt0346222,tt0089563,tt0097166,tt0086734�K\u0001���\u000fnm0002337\tRoger�K\u0001���?Marker\t1899\t1990\teditor\ttt0030760,tt0031774,tt0037536,tt0050562�K\u0001���\u0010nm0002373\tJanice�K\u0001���\u000fnm0002383\tMyron�K\u0001���^Themmen\t1959\t\\N\tactor,miscellaneous,assistant_director\ttt2330912,tt0067992,tt0491152,tt2198243�K\u0001���`Stone\t1945\t\\N\tcinematographer,camera_department,producer\ttt0364151,tt0383518,tt0283077,tt0107779�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002\u0010�\u0005�\u0005\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0005Haren�K\u0002���\u000enm0002428\tNick�K\u0001���\n",
      "nm0003314\tTim�K\u0001���JMorache\t1962\t\\N\tmake_up_department\ttt0157262,tt0119395,tt0120802,tt0092172�K\u0001���EGeddes\t1947\t\\N\tart_department\ttt0970416,tt0389564,tt0103442,tt0103502�K\u0001���CJr.\t\\N\t\\N\tcamera_department\ttt0438488,tt0096754,tt3397884,tt0477348�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002E�\u0005�:\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u000fnm0003327\tKaren�K\u0001���ONolan\t\\N\t\\N\teditor,editorial_department\ttt6791096,tt1823664,tt1292566,tt1632708�K\u0001���QRichards\t1965\t\\N\tdirector,writer,producer\ttt0319728,tt0227325,tt0127500,tt0847527�K\u0001���_Walsh\t\\N\t\\N\tproducer,production_manager,cinematographer\ttt2283336,tt0382992,tt0419887,tt1815862�K\u0001���\u000enm0003354\tJudy�K\u0001���\u0011nm0003356\tPatrick�K\u0001���ZHogan\t1890\t1943\tdirector,writer,assistant_director\ttt0025391,tt0029952,tt0022372,tt0017001�K\u0001���\u000enm0003379\tJohn�K\u0001���KSerpe\t1971\t\\N\twriter,director,actor\ttt0427449,tt0194421,tt4910718,tt0229400�K\u0001���\u000fnm0003390\tJosé�K\u0001��e.\u0000\u0000\u0017W\u0000\u0000\u0000\u0000\u0000\u0000\u0017S��\u0000\u0005ur\u0000\u0003[[BK�\u0019\u0015gg�7\u0002\u0000\u0000xp\u0000\u0000\u0000K\u0001���\u0012nm0003138\tNicholas�K\u0001���002961\tFrances�K\u0001���\u0012nm0002968\tDerubín�K\u0001���9Mena\t1975\t\\N\tproducer,director,writer\ttt0217907,tt0122419�K\u0001���UStraaten\t1971\t\\N\tactor,miscellaneous,producer\ttt6966758,tt0072331,tt0836827,tt0264235�K\u0001���fGuthrie\t1941\t\\N\tassistant_director,production_manager,producer\ttt0068149,tt0102070,tt0092319,tt0074464�K\u0001���\u0010nm0002986\tHoward�K\u0001���\u0007Lambert�K+���UWynter\t1965\t\\N\tdirector,miscellaneous,actress\ttt0208228,tt1267434,tt0248655,tt0200353�K\u0001���\u000enm0002991\tJill�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002:�\u0005�/\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�VKarnet\t\\N\t\\N\tproduction_designer,set_decorator\ttt0102851,tt0100521,tt0094371,tt0218306�K\u0001���\n",
      "nm0004240\tTom�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001��\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0010nm0004241\tDonald�K\u0001���NHipp\t1963\t\\N\tactor,soundtrack,composer\ttt0119094,tt0119668,tt0104714,tt0103759�K\u0001���VKramer\t1957\t\\N\tstunts,assistant_director,actor\ttt0093260,tt0079945,tt0093773,tt2820852�K\u0001���\u0011nm0004281\tStephen�K\u0001���\u0012nm0004290\tMargaret�K\u0001���NFine\t1902\t1975\tactor,soundtrack,writer\ttt0042012,tt0052880,tt0044007,tt0056579�K\u0001���\u000fnm0004314\tAngie�K\u0001���\u000fnm0004319\tSarah�K\u0001���\u0012nm0004324\tCaroline�K\u0001���SLeritz\t1962\t\\N\tactor,miscellaneous,producer\ttt7620960,tt6679470,tt6735740,tt1385826�K\u0001��e.\u0000\u0000\u0015n\u0000\u0000\u0000\u0000\u0000\u0000\u0015j��\u0000\u0005ur\u0000\u0003[[BK�\u0019\u0015gg�7\u0002\u0000\u0000xp\u0000\u0000\u0000\ttt1440129,tt0181689,tt0379786,tt1133985�K\u0001���?Blanc\t1919\t2009\tactress\ttt0855815,tt0032801,tt0046083,tt0250573�K\u0001���_Spiegel\t\\N\t\\N\tproduction_manager,producer,miscellaneous\ttt0318997,tt5722190,tt5071412,tt4903242�K\u0001���\u000enm0003642\tJeff�K\u0001���\u000enm0003648\tPaul�K\u0001���fPapamichael\t1962\t\\N\tcinematographer,camera_department,director\ttt0358273,tt1821549,tt5265790,tt1063056�K\u0001���RYost\t1959\t\\N\tproducer,writer,miscellaneous\ttt0111257,tt1489428,tt0374463,tt0120570�K\u0001���ZDenise\t\\N\t\\N\tvisual_effects,producer,miscellaneous\ttt1409024,tt0083658,tt0118884,tt0948470�K\u0001���\u000fnm0003682\tAkiva�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002`�\u0005�U\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u001cSalay\t\\N\t\\N\teditor\ttt0171827�K\u0001���cSyrokomla\t\\N\t\\N\tcostume_designer,costume_department,actress\ttt1160996,tt5066652,tt5672286,tt5773348�K\u0001���eLucidi\t1947\t\\N\teditor,editorial_department,production_manager\ttt0238012,tt0065374,tt0102070,tt0082716�K\u0001���\u000fnm0003750\tSteve�K\u0001���\u000fnm0003788\tPatti�K\u0001���\u0010nm0003798\tDonald�K\u0001���HForster\t1969\t\\N\tactress,producer\ttt0200427,tt0089287,tt0166924,tt0183505�K\u0001���KMatthews\t\\N\t\\N\tart_department,actor\ttt0298814,tt0283160,tt0118480,tt0183523�K\u0001���IPulver\t1929\t\\N\tactress,soundtrack\ttt0052656,tt0055256,tt0055070,tt0051200�K\u0001���\u001cRat\t\\N\t\\N\tcomposer\ttt0102420�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002\u000b�\u0005�\u0000\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u000fnm0003839\tAlain�K\u0001���\u000fnm0003854\tDiana�K\u0001���=Brian\t1875\t1948\tactor\ttt0029204,tt0007360,tt4846432,tt0006230�K\u0001���\u000enm0003867\tJohn�K\u0001���YHughes\t\\N\t\\N\teditorial_department,director,editor\ttt8289480,tt7573024,tt7016936,tt0436992�K\u0001���\u0011nm0003885\tKristen�K\u0001���YPalmisano\t1948\t\\N\tstunts,assistant_director,actor\ttt1833673,tt0293564,tt2016894,tt0266915�K\u0001���\u0010nm0003890\tMarcel�K\u0001���kLudovicy\t\\N\t\\N\tlocation_management,miscellaneous,production_manager\ttt0131646,tt0337103,tt0396171,tt0189998�K\u0001���\u000enm0003898\tKirk�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001��\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u000enm0003914\tBill�K\u0001���\u0010nm0003917\tKelley�K\u0001���\u000fnm0003949\tDavid�K\u0001���\u000fnm0003956\tDavid�K\u0001���\u000enm0003969\tJane�K\u0001���ZShore\t1974\t\\N\tcomposer,music_department,soundtrack\ttt6779076,tt9353248,tt4196868,tt3674910�K\u0001���\u000enm0003977\tGary�K\u0001���VColt\t\\N\t\\N\tactress,producer,assistant_director\ttt0101064,tt0120197,tt0108758,tt0200530�K\u0001���QKing\t\\N\t\\N\tvisual_effects,special_effects\ttt0296572,tt1034032,tt1133985,tt0120201�K\u0001���\u000fnm0004012\tSimon�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u00022�\u0005�'\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�/Lippy\t\\N\t\\N\tdirector,writer\ttt1391092,tt0241320�K\u0001���]Karyus\t1975\t\\N\tactor,camera_department,art_department\ttt4643048,tt2450186,tt0462485,tt2256858�K\u0001���\u0010nm0004043\tGeorge�K\u0001���TGustad\t1968\t\\N\tdirector,writer,miscellaneous\ttt0330082,tt0168529,tt0819646,tt3309662�K\u0001���\tChristian�M�\u0002���\u000fnm0004082\tGeoff�K\u0001���\u0010nm0004085\tHilary�K\u0001���\u000fnm0004086\tPenny�K\u0001���]Segal\t\\N\t\\N\tproducer,miscellaneous,production_manager\ttt1991564,tt0099385,tt0099422,tt0202745�K\u0001���WShannon\t\\N\t\\N\tsoundtrack,music_department,actor\ttt0105698,tt0103617,tt0103772,tt0075950�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002Ҁ\u0005��\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�NRuzzin\t1964\t\\N\tdirector,producer,actor\ttt0282965,tt0197570,tt0243970,tt0112540�K\u0001���\u000fnm0004116\tLarry�K\u0001���[Bondelli\t\\N\t\\N\teditor,editorial_department,producer\ttt0116409,tt0356150,tt0119190,tt0101055�K\u0001���\u0010nm0004121\tMikael�K\u0001���]Popovic\t\\N\t\\N\tcinematographer,camera_department,actor\ttt1389072,tt0126886,tt1821549,tt1033575�K\u0001���jEllingson\t\\N\t\\N\tart_department,visual_effects,animation_department\ttt0107290,tt0499549,tt1663662,tt0076759�K\u0001���^Fontijn\t\\N\t\\N\tmiscellaneous,actress,assistant_director\ttt0317919,tt0384766,tt0892318,tt0123095�K\u0001���ONobles\t1938\t\\N\twriter,producer,director\ttt0409811,tt0077099,tt0906763,tt0243609�K\u0001���3Geppi\t1967\t\\N\tactress\ttt0099329,tt0099073,tt0094155�K\u0001���\n",
      "nm0005363\tGuy�K\u0001���\u0011nm0005365\tVincent�K\u0001���WPeete\t1964\t\\N\tactress,music_department,producer\ttt0137302,tt0092312,tt1232829,tt0091225�K\u0001���\u0010nm0005373\tSmokey�K\u0001���\u0012nm0005397\tCristina�K\u0001���\u0010nm0005426\tRobert�K\u0001���Znm0005437\tSisqó\t1978\t\\N\tactor,soundtrack,composer\ttt0144528,tt2229499,tt0192071,tt0120812�K\u0001���OSmith\t1946\t\\N\tsoundtrack,actress,writer\ttt2062700,tt0088128,tt5109784,tt1959490�K\u0001��e.\u0000\u0000\u0018\"\u0000\u0000\u0000\u0000\u0000\u0000\u0018\u001e��\u0000\u0005ur\u0000\u0003[[BK�\u0019\u0015gg�7\u0002\u0000\u0000xp\u0000\u0000\u0000�_Frutkoff\t\\N\t\\N\tproduction_designer,art_department,actor\ttt0097637,tt0099365,tt0120780,tt0165854�K\u0001���\u000enm0004590\tWade�K\u0001���HCameron\t\\N\t\\N\tmake_up_department\ttt0097742,tt0293508,tt0120347,tt0311429�K\u0001���fNassour\t1947\t\\N\teditor,editorial_department,production_manager\ttt0046593,tt0075294,tt0081859,tt0083437�K\u0001���GOkrand\t1951\t\\N\tsound_department\ttt1442437,tt0093507,tt0125622,tt0089885�K\u0001���\u0006Sabato�K\u0001���\u000fnm0004655\tSalik�K\u0001���\u000fnm0004662\tPeter�K\u0001���\u000fnm0004679\tSerge�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002n�\u0005�c\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�ZAndretti\t1962\t\\N\tactor,camera_department,producer\ttt3777500,tt10083262,tt0132245,tt0115320�K\u0001���MAndrews\t1979\t\\N\tactor,director,writer\ttt0151738,tt0165710,tt0303816,tt0120789�K\u0001���\u000enm0004711\tMarc�K\u0001���LArnett\t1970\t\\N\tactor,producer,writer\ttt0367279,tt1490017,tt3398228,tt4116284�K\u0001���\u0010nm0004728\tCarole�K\u0001���QBentley\t1978\t\\N\tactor,producer,soundtrack\ttt1392170,tt0169547,tt0816692,tt0804516�K\u0001���ZBergman\t1929\t\\N\tmusic_department,soundtrack,writer\ttt0061811,tt0084805,tt0070903,tt0114319�K\u0001���\u000fnm0004755\tJason�K\u0001���;Bloom\t\\N\t\\N\tactress\ttt0115372,tt0111994,tt0176376,tt0187078�K\u0001���\u0012nm0004788\tRebeccah�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002��\u0005�}\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�MCardellini\t1975\t\\N\tactress,soundtrack\ttt0250494,tt0267913,tt2395427,tt0388795�K\u0001���\u000enm0004804\tDrew�K\u0001���?Carpenter\t1977\t\\N\tactor\ttt0108876,tt0164114,tt0200027,tt0247081�K\u0001���GChampa\t1968\t\\N\tactress,producer\ttt0112883,tt1421051,tt0102614,tt0112022�K\u0001���\u0010nm0004830\tTamara�K\u0001���OCombs\t1969\t\\N\tsoundtrack,producer,actor\ttt1226229,tt0285742,tt0172156,tt0120685�K\u0001���ICurtin\t1947\t\\N\tactress,soundtrack\ttt0086742,tt1155056,tt0115082,tt0106598�K\u0001���ODonahue\t1935\t\\N\tactor,producer,director\ttt1272033,tt0065335,tt0086827,tt1068634�K\u0001���\u000enm0004885\tFred�K\u0001���LDuke\t1943\t\\N\tdirector,actor,producer\ttt6998518,tt0088944,tt0093773,tt0242445�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002t�\u0005�i\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�bDunning\t1966\t\\N\tactress,animation_department,miscellaneous\ttt0859215,tt0101120,tt0312324,tt0116861�K\u0001���ODurst\t1970\t\\N\tsoundtrack,actor,director\ttt0146675,tt0232500,tt0783515,tt0433035�K\u0001���=Johnson\t\\N\t\\N\tactress\ttt5881326,tt0106123,tt1723121,tt2776704�K\u0001���\u0011nm0004920\tFrances�K\u0001���PFisher\t1952\t\\N\tactress,camera_department\ttt0139668,tt0105695,tt1189340,tt0120338�K\u0001���YFogerty\t1945\t\\N\tsoundtrack,music_department,actor\ttt1386697,tt0337978,tt1234719,tt1440129�K\u0001���\u000enm0004929\tDave�K\u0001���\u0004Moon�K����VGill\t1957\t\\N\tsoundtrack,actor,music_department\ttt0443453,tt0110478,tt0107211,tt0104438�K\u0001���\u000enm0004966\tBill�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002\u0017�\u0005�\f\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u000enm0004969\tJill�K\u0001���\u000enm0004970\tJade�K\u0001���\u0010nm0004984\tDeidre�K\u0001���\u000enm0004998\tLisa�K\u0001���THennessy\t1968\t\\N\tactress,soundtrack,director\ttt0242445,tt0098844,tt0284718,tt0486946�K\u0001���=Huber\t1975\t\\N\tactress\ttt0192917,tt0284787,tt0081857,tt0138968�K\u0001���YHynde\t1951\t\\N\tsoundtrack,actress,music_department\ttt0366548,tt0093428,tt0780536,tt0382992�K\u0001���OJackson\t1978\t\\N\tactor,director,producer\ttt0109520,tt0118300,tt1119644,tt2699110�K\u0001���@Jennings\t1965\t\\N\tactress\ttt0118484,tt0099423,tt0114369,tt0118475�K\u0001���\u000enm0005081\tMary�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001��\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u000fnm0005087\tLeila�K\u0001���\u000enm0005089\tBoyd�K\u0001���@Kingston\t1963\t\\N\tactress\ttt0426883,tt1117666,tt0436992,tt0108757�K\u0001���\u000fnm0005099\tHeidi�K\u0001���\u000enm0005109\tMila�K\u0001���\u000fnm0005134\tJason�K\u0001���\u0011nm0005138\tKristin�K\u0001���PLiddy\t1930\t\\N\tactor,writer,miscellaneous\ttt0160797,tt0100705,tt0086759,tt0221728�K\u0001���\u000enm0005165\tChad�K\u0001���]Manterola\t1972\t\\N\tactress,soundtrack,music_department\ttt0246498,tt0473102,tt0811069,tt1730842�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001��\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0010nm0005192\tKellie�K\u0001���SMasterson\t1976\t\\N\tactor,producer,soundtrack\ttt1068680,tt0165598,tt0219653,tt0119094�K\u0001���\n",
      "nm0005926\tJan�K\u0001���\\Artemev\t1937\t\\N\tcomposer,soundtrack,music_department\ttt0488478,tt0069293,tt0079944,tt5202654�K\u0001���]Astley\t1922\t1998\tcomposer,music_department,soundtrack\ttt0063893,tt0052611,tt0120053,tt2293640�K\u0001���\u0013nm0005971\tHans-Otto�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001��\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0011nm0005992\tGérard�K\u0001���\u0012nm0005995\tFiorenzo�K\u0001���\u000enm0006012\tElia�K\u0001���\u0010nm0006029\tManuel�K\u0001���ZVol\t1911\t1999\tmusic_department,soundtrack,composer\ttt0061735,tt0056687,tt0405336,tt0058213�K\u0001���\u000enm0006036\tPaul�K\u0001���\u000fnm0006038\tJames�K\u0001���^Dompierre\t1943\t\\N\tcomposer,soundtrack,music_department\ttt0089567,tt0116554,tt0087683,tt0207363�K\u0001���\u000fnm0006045\tSteve�K\u0001���\u0011nm0006054\tAntonio�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002Z�\u0005�O\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u0005Díaz�M�\u0002���]Eidelman\t1964\t\\N\tcomposer,music_department,soundtrack\ttt0403508,tt0120776,tt1001508,tt0102975�K\u0001���[Fiedel\t1951\t\\N\tmusic_department,composer,soundtrack\ttt0103064,tt0088247,tt0111503,tt0089175�K\u0001���[Franke\t1953\t\\N\tcomposer,music_department,soundtrack\ttt0285335,tt1191111,tt0367089,tt0105698�K\u0001���\u000enm0006087\tHugo�K\u0001���VGainsbourg\t1928\t1991\tsoundtrack,composer,actor\ttt0462322,tt0086654,tt1259014,tt0073196�K\u0001���\u0010nm0006106\tElliot�K\u0001���\u000fnm0006133\tJames�K\u0001���\u000enm0006149\tDana�K\u0001���ZMcHugh\t1893\t1969\tsoundtrack,music_department,actor\ttt0120663,tt0053125,tt0026942,tt0088933�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002��\u0005��\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u000fnm0006194\tAlois�K\u0001���\u000fnm0006203\tCyril�K\u0001���\u000enm0006208\tFred�K\u0001���`Piazzolla\t1921\t1992\tmusic_department,soundtrack,composer\ttt0095174,tt0091828,tt0114746,tt0090125�K\u0001���_Piccioni\t1921\t2004\tcomposer,soundtrack,music_department\ttt0057345,tt0073817,tt0118715,tt1045658�K\u0001���[Portal\t1935\t\\N\tcomposer,music_department,soundtrack\ttt0084589,tt0085312,tt0088844,tt0092739�K\u0001���]Preisner\t1955\t\\N\tcomposer,music_department,soundtrack\ttt0108394,tt0108071,tt0101765,tt0111495�K\u0001���\u000enm0006248\tErno�K\u0001���\\Rosen\t1906\t1994\tmusic_department,soundtrack,composer\ttt0038134,tt0213670,tt0034684,tt0037114�K\u0001���ZSarde\t1948\t\\N\tcomposer,soundtrack,music_department\ttt0074184,tt0074811,tt0073219,tt0100054�K\u0001��e.\u0000\u0000\u0015�\u0000\u0000\u0000\u0000\u0000\u0000\u0015���\u0000\u0005ur\u0000\u0003[[BK�\u0019\u0015gg�7\u0002\u0000\u0000xp\u0000\u0000\u000002926,tt0076759�K\u0001���\n",
      "nm0006710\tVik�K\u0001���:Sahay\t\\N\t\\N\tactor,soundtrack\ttt0934814,tt1605630,tt0907674�K\u0001���\u000enm0006716\tSeth�K\u0001���eHooper\t\\N\t\\N\tspecial_effects,make_up_department,miscellaneous\ttt0089489,tt0113762,tt0114608,tt0098375�K\u0001���\u000fnm0006724\tHazel�K\u0001���\u000fnm0006732\tNancy�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001�\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u000fnm0006734\tAlain�K\u0001���MTudela\t1966\t\\N\tdirector,editor,writer\ttt0264546,tt7471650,tt0264427,tt1863316�K\u0001���:C.H.\t\\N\t1984\tactor\ttt0240631,tt0259607,tt0279943,tt0280786�K\u0001���ZHoffmann\t1776\t1822\twriter,soundtrack,miscellaneous\ttt5523010,tt6179458,tt3998516,tt1563152�K\u0001���\u000fnm0006800\tSandy�K\u0001���\u000enm0006822\tJose�K\u0001���PRosse\t\\N\t\\N\tart_department,set_decorator\ttt0097216,tt0107096,tt0095316,tt0096501�K\u0001���\u0010nm0006833\tThomas�K\u0001���\u000enm0006839\tHugh�K\u0001���\u0010nm0006849\tJoanna�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001ƀ\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�THunter\t1947\t\\N\tdirector,writer,miscellaneous\ttt0337619,tt0108026,tt3749900,tt0091860�K\u0001���OVreugde\t\\N\t\\N\ttransportation_department\ttt3967856,tt1318514,tt0822854,tt0343818�K\u0001���\u0010nm0006882\tThomas�K\u0001���\fnm0006887\tR.�K\u0001���\u0010nm0006896\tAndrew�K\u0001���\u000fnm0006911\tSteve�K\u0001���\u000enm0006914\tDawn�K\u0001���fMarsicano\t1971\t\\N\tassistant_director,casting_director,director\ttt0241657,tt0818592,tt5974052,tt0268992�K\u0001���\u000fnm0006944\tChaim�K\u0001���\u000fnm0006955\tLewis�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0001�\u0005��\u0001\u0000\u0000\u0000\u0000\u0000\u0000]�(�MBrennan\t1956\t\\N\tactor,writer,producer\ttt0118702,tt0214101,tt0093011,tt0202470�K\u0001���\u000enm0006976\tMarc�K\u0001���\u000enm0006986\tMary�K\u0001���\u000enm0006988\tT.J.�K\u0001���ZJephcott\t1944\t\\N\tactor,production_manager,producer\ttt1798233,tt2018069,tt2258261,tt2261889�K\u0001���\u000enm0006993\tAlex�K\u0001���(Woodbury\t\\N\t\\N\tdirector,writer\ttt0233929�K\u0001���5Maged\t\\N\t\\N\tactor,director,writer\ttt1808441,tt0194710�K\u0001���\u000enm0007030\tDean�K\u0001���NCampbell\t\\N\t\\N\tactor,assistant_director,producer\ttt0262396,tt3480942,tt4073054�K\u0001��e.uq\u0000~\u0000\u0002\u0000\u0000\u0002��\u0005��\u0002\u0000\u0000\u0000\u0000\u0000\u0000]�(�\u000fnm0007080\tJamie�K\u0001���=O'Connor\t1963\t\\N\tactor,composer\ttt0116330,tt0221691,tt0120316�K\u0001���HBozeman\t\\N\t\\N\tcostume_department\ttt0120647,tt0113277,tt0162222,tt0114369�K\u0001���WPatekar\t1951\t\\N\tactor,music_department,director\ttt0451631,tt0476884,tt0476527,tt0110280�K\u0001���OLord\t1926\t2012\twriter,producer,director\ttt0056777,tt0052478,tt0044259,tt0065317�K\u0001���ZMartinovic\t\\N\t\\N\tcinematographer,camera_department\ttt2401256,tt1856010,tt4284010,tt1767382�K\u0001���XMorneau\t\\N\t\\N\tdirector,assistant_director,writer\ttt0117468,tt0175877,tt1987028,tt1140941�K\u0001���\u0011nm0007136\tMichael�K\u0001���\u0004Paul�Ms\n",
      "���SYoung\t1956\t\\N\tactor,writer,music_department\ttt0157465,tt0277986,tt0117533,tt0079549�K\u0001��e.\u0000\u0000\u0012�\u0000\u0000\u0000\u0000\u0000\u0000\u0012ì�\u0000\u0005ur\u0000\u0003[[BK�\u0019\u0015gg�7\u0002\u0000\u0000xp\u0000\u0000\u0000\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp/output1\n",
    "!head /tmp/output1/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8b5ec-b799-4177-8e4a-80a583d995e7",
   "metadata": {},
   "source": [
    "Poniższy paragraf zapisuje metryki po uruchomieniu Twojego rozwiązania *misji głównej*. \n",
    "\n",
    "Nie musisz go uruchamiać podczas implementacji rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4325d378-b145-4e8f-8d37-80a072b506c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "after_rdd_metrics = get_current_metrics(spark_ui_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28137d3d-6f0d-443f-97b8-38104aaced6d",
   "metadata": {},
   "source": [
    "# Część 2 - Spark SQL (DataFrame)\n",
    "\n",
    "## Misje poboczne\n",
    "\n",
    "W ponizszych paragrafach wprowadź swoje rozwiązania *misji pobocznych*, o ile **nie** chcesz, aby oceniana była *misja główna*. W przeciwnym przypadku **KONIECZNIE** pozostaw je **puste**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d045dae-5826-4015-8833-564d356db1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7738406-c426-4238-b0fb-983f4585bc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e7e569f-5f6b-4a98-b177-1b6fb0fc3333",
   "metadata": {},
   "source": [
    "## Misja główna \n",
    "\n",
    "Poniższy paragraf zapisuje metryki przed uruchomieniem Twojego rozwiązania *misji głównej*. \n",
    "\n",
    "Nie musisz go uruchamiać podczas implementacji rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6329c04b-3e50-41a8-93f1-333ac0ea64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "before_df_metrics = get_current_metrics(spark_ui_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cfb0d-51b6-45bb-b173-ab8ac630d4f3",
   "metadata": {},
   "source": [
    "W poniższych paragrafach wprowadź **rozwiązanie** *misji głównej* swojego projektu oparte o *DataFrame API*. \n",
    "\n",
    "Pamiętaj o wydajności Twojego przetwarzania, *DataFrame API* nie jest w stanie wszystkiego \"naprawić\". \n",
    "\n",
    "Nie wprowadzaj w poniższych paragrafach żadnego kodu, w przypadku wykorzystania *misji pobocznych*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eca6e627-0ce5-4c48-b441-3bcc14e32f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, split, count, desc\n",
    "# Wczytanie danych\n",
    "datasource1 = spark.read.option(\"sep\", \"\\t\").csv(datasource1_dir, inferSchema=True)\n",
    "datasource4 = spark.read.option(\"sep\", \"\\t\").csv(datasource4_dir, header=True, inferSchema=True)\n",
    "datasource1 = datasource1.toDF(\"tconst\", \"ordering\", \"nconst\", \"role\", \"job\", \"characters\")\n",
    "datasource4 = datasource4.toDF(\"nconst\", \"primaryName\", \"birthYear\", \"deathYear\", \"primaryProfession\", \"knownForTitles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4aaa9-8dc2-4726-871e-5e2450ba3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_set, size, array_contains, row_number, when\n",
    "from pyspark.sql import Window\n",
    "\n",
    "normalized_roles = datasource1.withColumn(\n",
    "    \"normalized_role\",\n",
    "    when(col(\"role\").isin(\"actor\", \"actress\", \"self\"), \"performer\").otherwise(col(\"role\"))\n",
    ")\n",
    "\n",
    "full_cast = normalized_roles.groupBy(\"tconst\").agg(collect_set(\"normalized_role\").alias(\"roles\")).\\\n",
    "    filter(\n",
    "        array_contains(col(\"roles\"), \"performer\") & \n",
    "        array_contains(col(\"roles\"), \"director\") & \n",
    "        (size(col(\"roles\")) > 3)\n",
    "    ).select(\"tconst\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ffba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------------+\n",
      "|   tconst|   nconst|           role|\n",
      "+---------+---------+---------------+\n",
      "|tt0000725|nm0226992|          actor|\n",
      "|tt0000725|nm0366008|          actor|\n",
      "|tt0000725|nm0000428|         writer|\n",
      "|tt0000725|nm0005658|cinematographer|\n",
      "|tt0000725|nm0567363|       director|\n",
      "|tt0000861|nm0732651|        actress|\n",
      "|tt0000861|nm0784407|          actor|\n",
      "|tt0000861|nm0005658|cinematographer|\n",
      "|tt0000861|nm0163559|          actor|\n",
      "|tt0000861|nm0000428|       director|\n",
      "|tt0000861|nm0456804|          actor|\n",
      "|tt0000861|nm0910400|          actor|\n",
      "|tt0000861|nm0253652|         writer|\n",
      "|tt0000861|nm0642722|          actor|\n",
      "|tt0000861|nm0940488|         writer|\n",
      "|tt0000862|nm0386036|          actor|\n",
      "|tt0000862|nm0264569|        actress|\n",
      "|tt0000862|nm5289829|          actor|\n",
      "|tt0000862|nm0511080|          actor|\n",
      "|tt0000862|nm0878467|       director|\n",
      "+---------+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Połączenie z datasource1 dla pełnej obsady\n",
    "full_cast_roles = full_cast.join(datasource1, \"tconst\").select(\"tconst\", \"nconst\", \"role\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498302a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+------+\n",
      "|   nconst|     profession|movies|\n",
      "+---------+---------------+------+\n",
      "|nm0577476|          actor|    16|\n",
      "|nm0232704|        actress|     2|\n",
      "|nm0852794|cinematographer|     2|\n",
      "|nm0430756|         writer|    66|\n",
      "|nm0354894|         writer|     7|\n",
      "|nm0001273|        actress|    57|\n",
      "|nm0222369|        actress|     2|\n",
      "|nm0294571|        actress|    12|\n",
      "|nm0746704|        actress|     4|\n",
      "|nm0376221|       director|   102|\n",
      "|nm0415405|        actress|     1|\n",
      "|nm0319702|cinematographer|    26|\n",
      "|nm0253296|       director|     7|\n",
      "|nm0299343|         writer|    52|\n",
      "|nm0221488|          actor|    69|\n",
      "|nm0384716|        actress|    21|\n",
      "|nm0006297|       composer|    37|\n",
      "|nm0622404|          actor|    16|\n",
      "|nm0518711|         writer|   193|\n",
      "|nm0703642|       producer|    94|\n",
      "+---------+---------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_cast_roles_count = full_cast_roles.groupBy(\"nconst\", \"role\").agg(count(\"tconst\").alias(\"movies\")).\\\n",
    "    select(\"nconst\", col(\"role\").alias(\"profession\"), \"movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571177a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------+---------+--------------------+--------------------+----------+\n",
      "|   nconst|    primaryName|birthYear|deathYear|   primaryProfession|      knownForTitles|profession|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+----------+\n",
      "|nm0000001|   Fred Astaire|     1899|     1987|soundtrack,actor,...|tt0072308,tt00430...|soundtrack|\n",
      "|nm0000001|   Fred Astaire|     1899|     1987|soundtrack,actor,...|tt0072308,tt00430...|     actor|\n",
      "|nm0000002|  Lauren Bacall|     1924|     2014|  actress,soundtrack|tt0038355,tt01170...|   actress|\n",
      "|nm0000002|  Lauren Bacall|     1924|     2014|  actress,soundtrack|tt0038355,tt01170...|soundtrack|\n",
      "|nm0000003|Brigitte Bardot|     1934|       \\N|actress,soundtrac...|tt0057345,tt00544...|   actress|\n",
      "|nm0000003|Brigitte Bardot|     1934|       \\N|actress,soundtrac...|tt0057345,tt00544...|soundtrack|\n",
      "|nm0000003|Brigitte Bardot|     1934|       \\N|actress,soundtrac...|tt0057345,tt00544...|  producer|\n",
      "|nm0000004|   John Belushi|     1949|     1982|actor,writer,soun...|tt0078723,tt00779...|     actor|\n",
      "|nm0000004|   John Belushi|     1949|     1982|actor,writer,soun...|tt0078723,tt00779...|    writer|\n",
      "|nm0000004|   John Belushi|     1949|     1982|actor,writer,soun...|tt0078723,tt00779...|soundtrack|\n",
      "|nm0000005| Ingmar Bergman|     1918|     2007|writer,director,a...|tt0050986,tt00509...|    writer|\n",
      "|nm0000005| Ingmar Bergman|     1918|     2007|writer,director,a...|tt0050986,tt00509...|  director|\n",
      "|nm0000005| Ingmar Bergman|     1918|     2007|writer,director,a...|tt0050986,tt00509...|     actor|\n",
      "|nm0000006| Ingrid Bergman|     1915|     1982|actress,soundtrac...|tt0036855,tt00381...|   actress|\n",
      "|nm0000006| Ingrid Bergman|     1915|     1982|actress,soundtrac...|tt0036855,tt00381...|soundtrack|\n",
      "|nm0000006| Ingrid Bergman|     1915|     1982|actress,soundtrac...|tt0036855,tt00381...|  producer|\n",
      "|nm0000007|Humphrey Bogart|     1899|     1957|actor,soundtrack,...|tt0043265,tt00373...|     actor|\n",
      "|nm0000007|Humphrey Bogart|     1899|     1957|actor,soundtrack,...|tt0043265,tt00373...|soundtrack|\n",
      "|nm0000007|Humphrey Bogart|     1899|     1957|actor,soundtrack,...|tt0043265,tt00373...|  producer|\n",
      "|nm0000008|  Marlon Brando|     1924|     2004|actor,soundtrack,...|tt0068646,tt00472...|     actor|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Przetwarzanie datasource4: Rozdzielanie profesji\n",
    "actor_data = datasource4.withColumn(\"profession\", explode(split(col(\"primaryProfession\"), \",\"))).\\\n",
    "    filter(col(\"profession\") != \"miscellaneous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad5f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|profession|  count|\n",
      "+----------+-------+\n",
      "|     actor|2259212|\n",
      "|   actress|1354336|\n",
      "|  producer| 845163|\n",
      "|    writer| 641773|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Najpopularniejsze profesje\n",
    "top_professions = actor_data.groupBy(\"profession\").agg(count(\"nconst\").alias(\"count\")).orderBy(desc(\"count\")).limit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a219e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_per_person = full_cast_roles_count.join(datasource4.select(\"nconst\", \"primaryName\"), \"nconst\").join(top_professions, \"profession\")\n",
    "window_spec = Window.partitionBy(\"profession\").orderBy(desc(\"movies\"))\n",
    "ranked_movies_per_person2 = movies_per_person.withColumn(\n",
    "    \"rank\", row_number().over(window_spec)\n",
    ")\n",
    "final_result = ranked_movies_per_person2.filter(col(\"rank\") <= 3).\\\n",
    "    select(\"profession\", \"primaryName\", \"movies\").orderBy(\"profession\", desc(\"movies\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a5755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------+\n",
      "|profession|       primaryName|movies|\n",
      "+----------+------------------+------+\n",
      "|     actor|Luis Eduardo Motoa|  3559|\n",
      "|     actor|         Ronit Roy|  2602|\n",
      "|     actor|       Dilip Joshi|  2385|\n",
      "|   actress|Luz Stella Luengas|  3636|\n",
      "|   actress| Rohini Hattangadi|  3240|\n",
      "|   actress|        Kavita Lad|  3204|\n",
      "|  producer|     Shobha Kapoor| 11833|\n",
      "|  producer|       Ekta Kapoor|  8826|\n",
      "|  producer| Valentin Pimstein|  6081|\n",
      "|    writer|       Tony Warren|  6153|\n",
      "|    writer|      Delia Fiallo|  6132|\n",
      "|    writer|     Sampurn Anand|  5205|\n",
      "+----------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45165cca-5197-4590-ba69-7541085147f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis wyników do tabeli \n",
    "final_result.write.mode(\"overwrite\").format(\"delta\").saveAsTable(df_result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0797752-450e-4f8f-a1d4-93a890a62c3d",
   "metadata": {},
   "source": [
    "Poniższy paragraf zapisuje metryki po uruchomieniu Twojego rozwiązania *misji głównej*. \n",
    "\n",
    "Nie musisz go uruchamiać podczas implementacji rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3647eae-2801-46ac-b43d-74e5bbfcab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIE ZMIENIAĆ\n",
    "after_df_metrics = get_current_metrics(spark_ui_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed01aa-cc23-427e-84c8-e5b76b9323bb",
   "metadata": {},
   "source": [
    "# Część 3 - Pandas API on Spark\n",
    "\n",
    "Ta część to wyzwanie. W szczególności dla osób, które nie programują na co dzień w Pythonie, lub które nie nie korzystały do tej pory z Pandas API.  \n",
    "\n",
    "Powodzenia!\n",
    "\n",
    "## Misje poboczne\n",
    "\n",
    "W ponizszych paragrafach wprowadź swoje rozwiązania *misji pobocznych*, o ile **nie** chcesz, aby oceniana była *misja główna*. W przeciwnym przypadku **KONIECZNIE** pozostaw je **puste**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a265f-db04-4a26-936d-18ab875ddffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91621654-a24e-4ddb-b2c7-9f149252af13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a5184ce-cf42-4342-aeec-b56c30b66bbd",
   "metadata": {},
   "source": [
    "## Misja główna \n",
    "\n",
    "Poniższy paragraf zapisuje metryki przed uruchomieniem Twojego rozwiązania *misji głównej*. \n",
    "\n",
    "Nie musisz go uruchamiać podczas implementacji rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63fd8306-87e9-46f2-b622-d60693e3ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NIE ZMIENIAĆ\n",
    "before_ps_metrics = get_current_metrics(spark_ui_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a967f079-7106-4bd7-9d26-98ced2aeb43b",
   "metadata": {},
   "source": [
    "W poniższych paragrafach wprowadź **rozwiązanie** swojego projektu oparte o *Pandas API on Spark*. \n",
    "\n",
    "Pamiętaj o wydajności Twojego przetwarzania, *Pandas API on Spark* nie jest w stanie wszystkiego \"naprawić\". \n",
    "\n",
    "Nie wprowadzaj w poniższych paragrafach żadnego kodu, w przypadku wykorzystania *misji pobocznych*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2094a69-30b1-4970-825b-2b0624436cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n",
      "/usr/local/spark/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_csv`, the default index is attached which can cause additional overhead.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    }
   ],
   "source": [
    "import pyspark.pandas as ps\n",
    "\n",
    "lines_ps = ps.read_csv(datasource4_dir, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea69e909-a557-4294-b1ae-f0d551649eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ps = lines_ps[0].apply(lambda x: x.split(' ') if x is not None else []).explode().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5759f50-b92e-41a5-9eb0-9b00e2528ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = words_ps.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b02917f4-e1f2-4fb4-8b53-8829fb3f0689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\pyspark\\pandas\\utils.py:975: PandasAPIOnSparkAdviceWarning: `to_pandas` loads all data into the driver's memory. It should only be used if the resulting pandas Series is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o331.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 14.0 failed 1 times, most recent failure: Lost task 5.0 in stage 14.0 (TID 72) (192.168.56.1 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.ArrowEvalPythonExec.evaluate(ArrowEvalPythonExec.scala:92)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:713)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:757)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:675)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:641)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:617)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:574)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:532)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 29 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.ArrowEvalPythonExec.evaluate(ArrowEvalPythonExec.scala:92)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:713)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:757)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:675)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:641)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:617)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:574)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:532)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 29 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m word_counts_pandas \u001b[38;5;241m=\u001b[39m word_counts\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m50\u001b[39m)\u001b[38;5;241m.\u001b[39mto_pandas()\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\pyspark\\pandas\\series.py:1692\u001b[0m, in \u001b[0;36mSeries.to_pandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;124;03mReturn a pandas Series.\u001b[39;00m\n\u001b[0;32m   1674\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03mName: dogs, dtype: float64\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m log_advice(\n\u001b[0;32m   1689\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`to_pandas` loads all data into the driver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms memory. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt should only be used if the resulting pandas Series is expected to be small.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1691\u001b[0m )\n\u001b[1;32m-> 1692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_pandas()\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\pyspark\\pandas\\series.py:1698\u001b[0m, in \u001b[0;36mSeries._to_pandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_pandas\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries:\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m \u001b[38;5;124;03m    Same as `to_pandas()`, without issuing the advice log for internal usage.\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_internal_pandas()\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\pyspark\\pandas\\series.py:7298\u001b[0m, in \u001b[0;36mSeries._to_internal_pandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   7292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_internal_pandas\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries:\n\u001b[0;32m   7293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   7294\u001b[0m \u001b[38;5;124;03m    Return a pandas Series directly from _internal to avoid overhead of copy.\u001b[39;00m\n\u001b[0;32m   7295\u001b[0m \n\u001b[0;32m   7296\u001b[0m \u001b[38;5;124;03m    This method is for internal use only.\u001b[39;00m\n\u001b[0;32m   7297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 7298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_psdf\u001b[38;5;241m.\u001b[39m_internal\u001b[38;5;241m.\u001b[39mto_pandas_frame[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname]\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\pyspark\\pandas\\utils.py:588\u001b[0m, in \u001b[0;36mlazy_property.<locals>.wrapped_lazy_property\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_lazy_property\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr_name):\n\u001b[1;32m--> 588\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr_name, fn(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr_name)\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\pyspark\\pandas\\internal.py:1056\u001b[0m, in \u001b[0;36mInternalFrame.to_pandas_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return as pandas DataFrame.\"\"\"\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m sdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_internal_spark_frame\n\u001b[1;32m-> 1056\u001b[0m pdf \u001b[38;5;241m=\u001b[39m sdf\u001b[38;5;241m.\u001b[39mtoPandas()\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pdf) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sdf\u001b[38;5;241m.\u001b[39mschema) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1058\u001b[0m     pdf \u001b[38;5;241m=\u001b[39m pdf\u001b[38;5;241m.\u001b[39mastype(\n\u001b[0;32m   1059\u001b[0m         {field\u001b[38;5;241m.\u001b[39mname: spark_type_to_pandas_dtype(field\u001b[38;5;241m.\u001b[39mdataType) \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m sdf\u001b[38;5;241m.\u001b[39mschema}\n\u001b[0;32m   1060\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:208\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect(), columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    209\u001b[0m column_counter \u001b[38;5;241m=\u001b[39m Counter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    211\u001b[0m corrected_dtypes: List[Optional[Type]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:1216\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[0;32m   1197\u001b[0m \n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[1;32m-> 1216\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mcollectToPython()\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o331.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 14.0 failed 1 times, most recent failure: Lost task 5.0 in stage 14.0 (TID 72) (192.168.56.1 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.ArrowEvalPythonExec.evaluate(ArrowEvalPythonExec.scala:92)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:713)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:757)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:675)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:641)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:617)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:574)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:532)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 29 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.ArrowEvalPythonExec.evaluate(ArrowEvalPythonExec.scala:92)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:713)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:757)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:675)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:641)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:617)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:574)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:532)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 29 more\r\n"
     ]
    }
   ],
   "source": [
    "word_counts_pandas = word_counts.head(50).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76e0d7f7-82f3-41d4-8267-cf288f2f6e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_pandas.to_json(ps_result_file, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a0ec5-ab13-4e39-a572-e7adf8b8556a",
   "metadata": {},
   "source": [
    "Poniższy paragraf zapisuje metryki po uruchomieniu Twojego rozwiązania *misji głównej*. \n",
    "\n",
    "Nie musisz go uruchamiać podczas implementacji rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "108bee2a-a847-4625-8e4a-939951ac9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NIE ZMIENIAĆ\n",
    "after_ps_metrics = get_current_metrics(spark_ui_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e266b-b5cd-41d0-aeab-c1edc365910d",
   "metadata": {},
   "source": [
    "# Analiza wyników i wydajności *misji głównych*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b67111-62d0-4657-b158-1ed37db9ed96",
   "metadata": {},
   "source": [
    "## Część 1 - Spark Core (RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cfc9900-7e0c-49ff-adba-e339f83ffe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TeriyakiApps\\x01~\\x01teriyakiapps@gmail.com\\x018589934594', 1)\n",
      "('Koza\\x01http://www.xynapse.pl\\x01xynapse@xynapse.pl\\x018589934595', 1)\n",
      "('Tools\\x01https://vcb30cb43.app-ads-txt.com/app-ads.txt\\x01androtools222@gmail.com\\x018589934596', 1)\n",
      "('Muslim', 110)\n",
      "('FireFlies', 2)\n",
      "('Studio\\x01~\\x01manuariza95@gmail.com\\x018589934602', 1)\n",
      "('News', 494)\n",
      "('IST-Development\\x01https://istanbulit.com\\x01info@istanbulit.com\\x018589934604', 1)\n",
      "('FAStuidoTI\\x01~\\x01karimkhalfy@gmail.com\\x018589934605', 1)\n",
      "('Web4Minds,', 1)\n",
      "('V3', 8)\n",
      "('Smart', 2437)\n",
      "('Ltd\\x01http://www.v3smarttech.com\\x01support@v3smarttech.com\\x018589934607', 1)\n",
      "('Mobil', 143)\n",
      "('UNDERSCORE:', 1)\n",
      "('Apps', 6350)\n",
      "('and', 5289)\n",
      "('Games\\x01~\\x01ergamesapps@gmail.com\\x018589934609', 1)\n",
      "('tamapps\\x01~\\x01zakdermeister@gmail.com\\x018589934614', 1)\n",
      "('S.', 397)\n",
      "('Connect', 331)\n",
      "('Team\\x01https://mewe.com/join/klwpdevelopersteam\\x01designcorpviti@gmail.com\\x018589934618', 1)\n",
      "('for', 2565)\n",
      "('with', 262)\n",
      "('NETWORKS', 23)\n",
      "('PTE', 226)\n",
      "('Art\\x01https://www.bytesart.site\\x01support@bytesart.tech\\x018589934624', 1)\n",
      "('Mother', 28)\n",
      "('ShowMeTheParts\\x01http://www.ShowMeTheParts.com\\x01showmetheparts@gmail.com\\x018589934628', 1)\n",
      "('Sitevenia\\x01http://www.wmphotos.fr\\x01williammoureaux@sfr.fr\\x018589934629', 1)\n",
      "('NOVATIVE\\x01https://www.novative.com/\\x01sales@novative.com\\x018589934634', 1)\n",
      "('Chokurei', 5)\n",
      "('everyone\\x01https://www.sistemaeducativofinanciero.com/p/privacy\\x01sanz112358@gmail.com\\x018589934635', 1)\n",
      "('Orotti', 1)\n",
      "('Apps\\x01http://www.orotti.com\\x01apps@orotti.com\\x018589934636', 1)\n",
      "('Rabbitz', 2)\n",
      "('Games\\x01~\\x01madrabbitzgames@gmail.com\\x018589934637', 1)\n",
      "('ParkerSoft\\x01~\\x01ianparker2007@yahoo.co.uk\\x018589934638', 1)\n",
      "('ISHAN', 5)\n",
      "('Bismania', 2)\n",
      "('Wei', 36)\n",
      "('Jie\\x01https://github.com/myluckynumbers/In-Between\\x01limweijie250@gmail.com\\x018589934644', 1)\n",
      "('Iraqi', 3)\n",
      "('Investment', 273)\n",
      "('MV', 59)\n",
      "('S/A\\x01http://www.mv.com.br\\x01inovacaomv@gmail.com\\x018589934646', 1)\n",
      "('Welfare', 43)\n",
      "('Gosa\\x01https://www.facebook.com/themexperia\\x01support@mkninc.ru\\x018589934648', 1)\n",
      "('Frillapps\\x01https://weedleapps.co.il/\\x01ozvi.inc@gmail.com\\x018589934651', 1)\n",
      "('Beansprites', 5)\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie wyników z pliku pickle\n",
    "word_counts = sc.pickleFile(rdd_result_dir)\n",
    "\n",
    "# Wyświetlenie 50 pierwszych elementów\n",
    "result_sample = word_counts.take(50)\n",
    "for item in result_sample:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16edae69-8062-4422-842f-d50bca0af9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numTasks': 6,\n",
       " 'numActiveTasks': 0,\n",
       " 'numCompleteTasks': 6,\n",
       " 'numFailedTasks': 0,\n",
       " 'numKilledTasks': 0,\n",
       " 'numCompletedIndices': 6,\n",
       " 'executorDeserializeTime': 763,\n",
       " 'executorDeserializeCpuTime': 288417800,\n",
       " 'executorRunTime': 52789,\n",
       " 'executorCpuTime': 3791290300,\n",
       " 'resultSize': 12143,\n",
       " 'jvmGcTime': 1808,\n",
       " 'resultSerializationTime': 19,\n",
       " 'memoryBytesSpilled': 0,\n",
       " 'diskBytesSpilled': 0,\n",
       " 'peakExecutionMemory': 0,\n",
       " 'inputBytes': 84276905,\n",
       " 'inputRecords': 1179547,\n",
       " 'outputBytes': 90624535,\n",
       " 'outputRecords': 14566,\n",
       " 'shuffleRemoteBlocksFetched': 0,\n",
       " 'shuffleLocalBlocksFetched': 9,\n",
       " 'shuffleFetchWaitTime': 0,\n",
       " 'shuffleRemoteBytesRead': 0,\n",
       " 'shuffleRemoteBytesReadToDisk': 0,\n",
       " 'shuffleLocalBytesRead': 49730906,\n",
       " 'shuffleReadBytes': 49730906,\n",
       " 'shuffleReadRecords': 228,\n",
       " 'shuffleWriteBytes': 49730906,\n",
       " 'shuffleWriteTime': 405851800,\n",
       " 'shuffleWriteRecords': 228}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtract_metrics(after_rdd_metrics, before_rdd_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc730f1-4b5e-4a68-8a86-11768918fcf4",
   "metadata": {},
   "source": [
    "## Część 2 - Spark SQL (DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b950a09d-045e-4143-a3cf-8ecc7c73ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+\n",
      "|                     word|count|\n",
      "+-------------------------+-----+\n",
      "|                      The| 9372|\n",
      "|                   Bidhee|    7|\n",
      "|                Solutions| 6041|\n",
      "|                   ArtAce|    2|\n",
      "|                  PuyTech|    1|\n",
      "|                   McLeod|  208|\n",
      "|                      RTV|   13|\n",
      "|     Software\u0001http://p...|    1|\n",
      "|紫荊雜誌社\u0001https://bau...|    1|\n",
      "|                  Bacilio|    2|\n",
      "|     Developer\u0001https:/...|    1|\n",
      "|     Software\u0001http://w...|    1|\n",
      "|                  Backend|   13|\n",
      "|하이퍼펌프\u0001~\u0001hyper.cho...|    1|\n",
      "|                    METRO|   21|\n",
      "|     ADBAND\u0001http://www...|    1|\n",
      "|                      Tcf|    1|\n",
      "|                      Pug|   12|\n",
      "|              Techologies|    4|\n",
      "|     Tourism\u0001https://t...|    1|\n",
      "|     Kinsale\u0001~\u0001gourmet...|    1|\n",
      "|     English\u0001https://w...|    1|\n",
      "|                    Darul|   10|\n",
      "|                       📱|    3|\n",
      "|                  Panipat|    2|\n",
      "|     Konyukhov\u0001http://...|    1|\n",
      "|                     Bold|   38|\n",
      "|     Developer\u0001http://...|    1|\n",
      "|     Advertising\u0001http:...|    1|\n",
      "|                 CÁNTABRO|    2|\n",
      "|     Consultores\u0001http:...|    1|\n",
      "|                     Amit|  106|\n",
      "|     CONTACTS\u0001http://w...|    1|\n",
      "|                    Jimmy|   78|\n",
      "|     applications\u0001~\u0001ph...|    1|\n",
      "|     Rechts\u0001https://ww...|    1|\n",
      "|     KetchapPro\u0001~\u0001ketc...|    1|\n",
      "|                     GIDA|    9|\n",
      "|     dev\u0001~\u0001radsdev@mai...|    1|\n",
      "|     Dipre\u0001~\u0001diomaris0...|    1|\n",
      "|                   Games:|   41|\n",
      "|                Beautiful|   62|\n",
      "|                      Jio|   22|\n",
      "|                   Phenix|   13|\n",
      "|     Apps\u0001https://seqa...|    1|\n",
      "|                    Qulam|    2|\n",
      "|     Games\u0001http://tinm...|    1|\n",
      "|     RedPACT\u0001~\u0001nancyak...|    1|\n",
      "|                     Coin|   79|\n",
      "|                 Smartify|    5|\n",
      "+-------------------------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.table(df_result_table)\n",
    "\n",
    "# Wyświetlenie 50 pierwszych rekordów\n",
    "df.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f344ed9-94c1-4d79-b839-1839548d8c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numTasks': 12,\n",
       " 'numActiveTasks': 0,\n",
       " 'numCompleteTasks': 8,\n",
       " 'numFailedTasks': 0,\n",
       " 'numKilledTasks': 0,\n",
       " 'numCompletedIndices': 8,\n",
       " 'executorDeserializeTime': 1254,\n",
       " 'executorDeserializeCpuTime': 446474600,\n",
       " 'executorRunTime': 54900,\n",
       " 'executorCpuTime': 22626614900,\n",
       " 'resultSize': 36185,\n",
       " 'jvmGcTime': 2428,\n",
       " 'resultSerializationTime': 110,\n",
       " 'memoryBytesSpilled': 0,\n",
       " 'diskBytesSpilled': 0,\n",
       " 'peakExecutionMemory': 440400752,\n",
       " 'inputBytes': 84344235,\n",
       " 'inputRecords': 1179547,\n",
       " 'outputBytes': 50321941,\n",
       " 'outputRecords': 1456441,\n",
       " 'shuffleRemoteBlocksFetched': 0,\n",
       " 'shuffleLocalBlocksFetched': 16,\n",
       " 'shuffleFetchWaitTime': 0,\n",
       " 'shuffleRemoteBytesRead': 0,\n",
       " 'shuffleRemoteBytesReadToDisk': 0,\n",
       " 'shuffleLocalBytesRead': 63406957,\n",
       " 'shuffleReadBytes': 63406957,\n",
       " 'shuffleReadRecords': 1622698,\n",
       " 'shuffleWriteBytes': 63406957,\n",
       " 'shuffleWriteTime': 817119700,\n",
       " 'shuffleWriteRecords': 1622698}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtract_metrics(after_df_metrics, before_df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063b46c-579d-4775-ba3f-837708279ea2",
   "metadata": {},
   "source": [
    "## Część 3 - Pandas API on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab5e31a2-fd31-40ca-be7b-b20b13dc38a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/studia/Semestr 7/Big Data/laby/projekt2/output3.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Odczytaj zawartość pliku JSON\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(ps_result_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      5\u001b[0m     json_content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Wyświetl zawartość\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kubag\\miniconda3\\envs\\data_science_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/studia/Semestr 7/Big Data/laby/projekt2/output3.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Odczytaj zawartość pliku JSON\n",
    "with open(ps_result_file, 'r') as file:\n",
    "    json_content = json.load(file)\n",
    "\n",
    "# Wyświetl zawartość\n",
    "print(json.dumps(json_content, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32788c91-3f8e-4fb1-8afc-5eb00938e687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numTasks': 33,\n",
       " 'numActiveTasks': 0,\n",
       " 'numCompleteTasks': 25,\n",
       " 'numFailedTasks': 0,\n",
       " 'numKilledTasks': 0,\n",
       " 'numCompletedIndices': 25,\n",
       " 'executorDeserializeTime': 1838,\n",
       " 'executorDeserializeCpuTime': 440241100,\n",
       " 'executorRunTime': 166601,\n",
       " 'executorCpuTime': 55323279000,\n",
       " 'resultSize': 134363,\n",
       " 'jvmGcTime': 4753,\n",
       " 'resultSerializationTime': 123,\n",
       " 'memoryBytesSpilled': 0,\n",
       " 'diskBytesSpilled': 0,\n",
       " 'peakExecutionMemory': 427817888,\n",
       " 'inputBytes': 385819487,\n",
       " 'inputRecords': 5409845,\n",
       " 'outputBytes': 0,\n",
       " 'outputRecords': 0,\n",
       " 'shuffleRemoteBlocksFetched': 0,\n",
       " 'shuffleLocalBlocksFetched': 20,\n",
       " 'shuffleFetchWaitTime': 0,\n",
       " 'shuffleRemoteBytesRead': 0,\n",
       " 'shuffleRemoteBytesReadToDisk': 0,\n",
       " 'shuffleLocalBytesRead': 61239298,\n",
       " 'shuffleReadBytes': 61239298,\n",
       " 'shuffleReadRecords': 1573467,\n",
       " 'shuffleWriteBytes': 61239298,\n",
       " 'shuffleWriteTime': 1111152100,\n",
       " 'shuffleWriteRecords': 1573467}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtract_metrics(after_ps_metrics, before_ps_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
